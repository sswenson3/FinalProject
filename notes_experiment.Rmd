---
title: "R Notebook"
output: html_notebook
---

Loading our Libraries 
```{r}
library(tidyverse)
library(tidytext)
library(hunspell)
library(glue)
library(gutenbergr)
library(ggplot2)
library(jsonlite)
library(httr)
```

Utility functions 
```{r}

#let me send in  lists of words as space separated strings for convenience
qq <- function(alist) {  list = strsplit(alist," ", fixed= T); list  = list[[1]] }


colorwords2 = function(df) {
    wordhist <- df %>% unnest_tokens(word,text) %>% 
        filter( word %in% c("white","black","red","yellow","green","blue","orange","indigo", "violet" ) ) %>% count(word)
    wordhist }




 
```



```{r}
# Load up the Latin Hunspell 
latin = dictionary("Data/la_LA.dic")
#TESTING 
# w = tibble ( verba = qq(
#   "Atra atrae Atrae atram atra ater atri atro atrum atro atrater atorum atris atrior atrissima atrissimum atrissimis" ) )
w = tibble ( verba = qq(
  "bonus bonum boni bonas bonis bonissimus bona bonae bonas" ) )
df <- w %>% mutate(
  stem=  hunspell_stem(verba, dict=latin )
) %>% unnest(stem)
w

df
```


Here we run into a problem there is ambiguity in the returned results.   So... we will ignore this for now and construct a concordance of stems associated with the adjectives we wish to use in our analysis. In this example the duplicates are all generated by alternate spellings of the same word.  We will use a dictionary to help us remove unrelated stems where they occur. 


### Generating  and cleaning concordanance Data 

Retrieving data from a declension generator for each of our selected words
filtering out unwanted text from that process 
creating the concordance for that word
adding to the concordance table.

Each word will create a declension file derived from the generator website 
```{r}
exampledeclension <- read_file("Data/ater.declension.raw")
exampledeclension
```
This raw file is then converted to string containing all forms of the word and then converted to a list of words. 
```{r}
declension <- exampledeclension 
declension<- str_replace_all(declension, ".*Adverb:.*\\r\\n","")
declension <- str_replace_all(declension, "\\r\\n|\\t|,"," ") 
declension <- str_replace_all(declension, "\\s+|\\r\\n|\\t|,"," ")
#get rid of unwanted characters from html table
declension <- str_replace_all(declension, "\\bm\\b|\\bf\\b|\\bn\\b|\\.|^.\\s+$|Nom|Gen|Dat|Acc|Abl|Voc|SINGULAR|PLURAL|Superlative|Comparative|","")
declension <- str_replace_all(declension, "\\s+"," ")  
declension <- str_replace_all(declension, "^\\s|\\s$","")
declension 

print (qq(declension))
```

 Finally, the forms are stemmed by the hunspell library and converted to a mini-concordance 

```{r}
english = "black"
verba = w <- tibble( verba = qq(declension)) %>% mutate(LatinStem = hunspell_stem(verba,dict = latin)) %>% unnest(LatinStem) %>% select(LatinStem ) %>% distinct() %>% mutate(English =glue({english}))

verba
```
 
 In this case for the word ater, I know that neither atrium nor atrivm are valid forms for this word
 so we remove those rows and then add them to our concordance 
 
```{r}
verba <- verba %>% filter(!LatinStem %in% qq("atrium atrivm"))

concordance <- verba
concordance
```
 
I introduce a function to do this cleanup work for each word.  It is still necessary to inspect the mini concordance before adding its rows to our concordance

```{r}

# Regular expression excluding all unwanted text from a declension table
# generated at https://latin.cactus2000.de/noun/shownoun_en.php?n=generator
# "^m|\sf\s|n$|,|\.|^.\s+$|Nom|Gen|Dat|Acc|Abl|Voc|SINGULAR|PLURAL|^Adverb.*$|Superlative|Comparative",""
string_declension <- function (verbum) {
    declension <- read_file(glue ("./Data/{verbum}.declension.raw"))
    #get rid of line control characters 
	  declension<- str_replace_all(declension, ".*Adverb:.*\\r\\n","")
    declension <- str_replace_all(declension, "\\r\\n|\\t|,"," ") 
    declension <- str_replace_all(declension, "\\s+|\\r\\n|\\t|,|/|-"," ")
    #get rid of unwanted characters from html table
    declension <- str_replace_all(declension, "\\bm\\b|\\bf\\b|\\bn\\b|\\.|^.\\s+$|Nom|Gen|Dat|Acc|Abl|Voc|SINGULAR|PLURAL|Superlative|Comparative|","")
	
    declension <- str_replace_all(declension, "\\s+"," ")

    declension <- str_replace_all(declension, "\\s+"," ")
	declension <- str_replace_all(declension, "^\\s|\\s$","")
}

get_declension <- function (verbum, english) {
    declension <- string_declension(glue({verbum}))
    w <- tibble( verba = qq(declension)) %>% mutate(LatinStem = hunspell_stem(verba,dict = latin))      %>% unnest(LatinStem) %>% select(LatinStem ) %>% distinct() %>% mutate(English =glue({english}))
}

```

 The selected words for our concordance are : 
 
 black, white, red, yellow, green, blue, purple, orange
 
 And a  collection of common Latin adjectives:
 kind, right (direction), left , bad, good, diligent, many, only,
 none, one, swift, strong,old  
```{r}

```
 
The hypothesis is that cross section of common descriptive words could give us a sense 
of faithfulness to an original edition or translation.  This approach can later be expanded by including synonyms in each language of interest and some context via NLP could assist in discriminating a bit further. 


 # Examine w , remove invalid stems , mutate to add the english word to concordance

```{r}
niger <- get_declension("niger","black")
niger


```

  This word has no ambiguous forms
  
 

```{r}
concordance <- add_row(concordance,niger)

albus <- get_declension("albus","white")
albus


```

This has two  ambiguous or invalid forms for the word I want: albeo, alboris 

```{r}
albus <- albus %>% filter(!LatinStem %in% qq("albeo alboris"))
concordance <- add_row(concordance, albus)

concordance

```

```{r}
ruber <- get_declension("ruber","red")
ruber
```
This has a single ambiguous stem 

```{r}
ruber <- ruber %>% filter(!LatinStem %in% qq("rubrus"))
concordance <- add_row(concordance, ruber)
concordance
```
```{r}
```


```{r}
flavus <- get_declension("flavus","yellow")
flavus
```
```{r}
flavus <- flavus %>% filter(!LatinStem %in% qq("flo flaveo"))
concordance <- add_row(concordance, flavus)
concordance

```

```{r}
fulvus <- get_declension("fulvus","yellow")
fulvus
```
```{r}
concordance <- add_row(concordance, fulvus)
concordance

```


```{r}
viridis <- get_declension("viridis","green")
viridis

```

```{r}
viridis <- viridis %>% filter(!LatinStem %in% qq("virido"))
concordance <- add_row(concordance, viridis)
concordance
```

```{r}
caeruleus <- get_declension("caeruleus","blue")
caeruleus

```

This is interesting.  This word has a compound comparative and superlative but preserves the earlier forms.  

```{r}
declension <- string_declension("caeruleus") 
declension
```
So, we'll just omit the helping adverb for blue for our concordance since the  unadorned stem will still appear anywhere it is used. 

```{r}
caeruleus <- caeruleus %>% filter( ! grepl("m.*",LatinStem))
caeruleus
concordance <- add_row(concordance, caeruleus)
concordance
```
The next word does the same thing so I only loaded the Positive declension into its file 
```{r}
croceus <- get_declension("croceus","orange")
croceus
```
```{r}
concordance <- add_row(concordance, croceus)
concordance

```
```{r}
purpureus <- get_declension("purpureus","purple")
purpureus
```
```{r}
concordance <- add_row(concordance, purpureus)
concordance
```

```{r}
amicus <- get_declension("amicus","kind")

```
```{r}
amicus <- amicus %>% filter(!LatinStem %in% qq("amicvi amicio"))
concordance<- add_row(concordance,amicus)
concordance
```

The word Dexter's declension is different.   It has alternate forms available in it's declension.  So I've refactored the declension utilities. Added the '/' as a delimiter to handle.

```{r}

declension <- read_file("Data/dexter.declension.raw")
declension<- str_replace_all(declension, ".*Adverb:.*\\r\\n","")
declension <- str_replace_all(declension, "\\r\\n|\\t|,"," ") 
declension <- str_replace_all(declension, "\\s+|\\r\\n|\\t|,"," ")
declension

```
```{r}
declension <- string_declension("dexter")
declension
```
That worked so proceeding as before. 
```{r}
dexter <- get_declension("dexter","right")
dexter
```
All of these are valid so adding to the concordance. 

```{r}
concordance<- add_row(concordance,dexter)
concordance
```
```{r}
sinister <- get_declension("sinister","left")
sinister
```
```{r}
concordance<- add_row(concordance,sinister)
concordance
```
Malus, or 'evil,bad' turns out to be irregular and changes its form. I find this amusing that evil doesn't follow the rules.  
```{r}
print(string_declension("malus"))
```
The declension doesn't appear to cause any problems with tools developed so far so we'll proceed as usual 

```{r}
malus <- get_declension("malus","bad")
malus
```
```{r}
malus <- malus %>% filter(! LatinStem %in% qq("peioro malvi ") )
concordance <- add_row (concordance, malus)
concordance

bonus <- get_declension("bonus","good")
bonus
```

```{r}
bonus <- bonus %>% filter(! LatinStem %in% qq("melioro melium") )
concordance <- add_row (concordance, bonus)
concordance

```
```{r}
diligens <- get_declension("diligens","diligent")
diligens
```

```{r}
diligens <- diligens %>% filter (! LatinStem %in% qq("diligo"))
concordance <- add_row(concordance,diligens)
concordance
```
We run into another issue in the irregulat declension of multus where certain forms don't exist and are represented by  - 

```{r}
declension <- read_file("Data/multus.declension.raw")
declension<- str_replace_all(declension, ".*Adverb:.*\\r\\n","")
declension <- str_replace_all(declension, "\\r\\n|\\t|,"," ") 
declension <- str_replace_all(declension, "\\s+|\\r\\n|\\t|,"," ")
declension

```
Added a rule to our regular expression 

```{r}
print(string_declension("multus"))
multus <- get_declension("multus","many")
multus 
```
And proceeded as usual 
```{r}
multus <- multus %>% filter (! LatinStem %in% qq("pluvi"))
concordance <- add_row(concordance,multus)
concordance
```

```{r}
solus <- get_declension("solus","only")
solus
```

```{r}
solus <- solus %>% filter (! LatinStem %in% qq("solvi soleo"))
concordance <- add_row(concordance,solus)
concordance
```

```{r}

declension <- read_file("Data/nullus.declension.raw")
declension<- str_replace_all(declension, ".*Adverb:.*\\r\\n","")
declension <- str_replace_all(declension, "\\r\\n|\\t|,"," ") 
declension <- str_replace_all(declension, "\\s+|\\r\\n|\\t|,"," ")
declension
```

Another twist. this time it will take manual intervention to clean it.
First we will collect all the words. remove the extraneous endings then add the missing forms and then stem the result into a mini-concordance, and verify for valid forms.  We will modify get_declension to accept verba as a list 
```{r}

```


